{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a52f11e2-b49a-bc82-fe03-765b797e63b7"
   },
   "source": [
    "First the data is loaded into Pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2f80e0fa-2b27-3d9c-49ab-c4130000d8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Read the input datasets\n",
    "train_data = pd.read_csv('../input/train.csv')\n",
    "test_data = pd.read_csv('../input/test.csv')\n",
    "\n",
    "# Fill missing numeric values with median for that column\n",
    "train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\n",
    "\n",
    "print(train_data.info())\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "37944f51-e2d4-2075-8a66-99312528bc3e"
   },
   "source": [
    "Next select a subset of our train_data to use for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "9906ca9e-d181-30b3-a90a-0bc6d87771fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 6)\n",
      "(891,)\n"
     ]
    }
   ],
   "source": [
    "# Encode sex as int 0=female, 1=male\n",
    "train_data['Sex'] = train_data['Sex'].apply(lambda x: int(x == 'male'))\n",
    "\n",
    "# Extract the features we want to use\n",
    "X = train_data[['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch']].as_matrix()\n",
    "print(np.shape(X))\n",
    "\n",
    "# Extract survival target\n",
    "y = train_data[['Survived']].values.ravel()\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b972cddf-01a5-e59e-a958-1aad99652ba6"
   },
   "source": [
    "Now train the SVM classifier and get validation accuracy using K-Folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "9cc858d1-dbd9-fb62-a4bb-de6760ec0688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 3-fold cross validation accuracy: 0.822671156004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Build the classifier\n",
    "kf = KFold(n_splits=3)\n",
    "model = SVC(kernel='rbf', C=300)\n",
    "\n",
    "scores = []\n",
    "for train, test in kf.split(X):\n",
    "    # Normalize training and test data using train data norm parameters\n",
    "    normalizer = MinMaxScaler().fit(X[train])\n",
    "    X_train = normalizer.transform(X[train])\n",
    "    X_test = normalizer.transform(X[test])\n",
    "    \n",
    "    scores.append(model.fit(X_train, y[train]).score(X_test, y[test]))\n",
    "    \n",
    "print(\"Mean 3-fold cross validation accuracy: %s\" % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ea285d26-6b55-dc59-4fe2-199171b94887"
   },
   "source": [
    "Make predictions on the test data and output the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "2320e2c6-43cd-12f8-f162-8bebcc121497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         1\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "5            897         0\n",
      "6            898         1\n",
      "7            899         0\n",
      "8            900         1\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         1\n",
      "19           911         1\n",
      "20           912         0\n",
      "21           913         0\n",
      "22           914         1\n",
      "23           915         0\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         1\n",
      "392         1284         0\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         0\n",
      "405         1297         0\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         1\n",
      "409         1301         1\n",
      "410         1302         1\n",
      "411         1303         1\n",
      "412         1304         1\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create model with all training data\n",
    "normalizer = MinMaxScaler().fit(X)\n",
    "X = normalizer.transform(X)\n",
    "classifier = model.fit(X, y)\n",
    "\n",
    "# Encode sex as int 0=female, 1=male\n",
    "test_data['Sex'] = test_data['Sex'].apply(lambda x: int(x == 'male'))\n",
    "\n",
    "# Extract desired features\n",
    "X_ = test_data[['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch']].as_matrix()\n",
    "X_ = normalizer.transform(X_)\n",
    "\n",
    "# Predict if passengers survived using model\n",
    "y_ = classifier.predict(X_)\n",
    "\n",
    "# Append the survived attribute to the test data\n",
    "test_data['Survived'] = y_\n",
    "predictions = test_data[['PassengerId', 'Survived']]\n",
    "print(predictions)\n",
    "\n",
    "# Save the output for submission\n",
    "predictions.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 97,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

